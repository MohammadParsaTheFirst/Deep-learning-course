{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<font face=\"Times New Roman\" size=5>\n",
        "<div dir=rtl align=\"center\">\n",
        "<font face=\"Times New Roman\" size=5>\n",
        "In The Name of God\n",
        "</font>\n",
        "<br>\n",
        "<img src=\"https://logoyar.com/content/wp-content/uploads/2021/04/sharif-university-logo.png\" alt=\"University Logo\" width=\"150\" height=\"150\">\n",
        "<br>\n",
        "<font face=\"Times New Roman\" size=4 align=center>\n",
        "Sharif University of Technology - Department of Electrical Engineering\n",
        "</font>\n",
        "<br>\n",
        "<font color=\"#008080\" size=6>\n",
        "Deep Learning \n",
        "</font>\n",
        "<hr/>\n",
        "<font color=\"#800080\" size=5>\n",
        "Assignment 7 : Introduction to Graph Neural Networks\n",
        "<br>\n",
        "</font>\n",
        "<font size=5>\n",
        "Instructor: Dr. M. Bejani\n",
        "<br>\n",
        "</font>\n",
        "<font size=4>\n",
        "Spring 2025\n",
        "<br>\n",
        "</font>\n",
        "<font face=\"Times New Roman\" size=4>\n",
        "Deadline: 10 Khordad 1404\n",
        "</font>\n",
        "<hr>\n",
        "<font color='red'  size=4>\n",
        "Note: It is highly recommended to run your notebook on Google Colab or Kaggle\n",
        "<br>\n",
        "</font>\n",
        "<font face=\"Times New Roman\" size=4 align=center>\n",
        "Feel free to ask your questions in Telegram : @yasinsala\n",
        "</font>\n",
        "<br>\n",
        "<hr>\n",
        "</div></font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Pytorch Geometric Framework\n",
        "- In this homework you get to familair with Pytorch Geometric (PyG) framework.\n",
        "- Showcase the implementation of **Graph Convolution Networks** (Kipf & Welling, [SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS](https://arxiv.org/abs/1609.02907), ICLR 2017), and you should implement **GraphSAGE** (Hamilton et al, [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216), NIPS 2017) (You do not need to read the paper, just follow the hints).\n",
        "\n",
        "#### 2. Vertex Classification\n",
        "- Showcase a model developed based on our GCN implementation to do vertex classification on Cora dataset. \n",
        "- Develop a model with **your own** GraphSAGE (with mean/sum/max aggregation) implementation on the same dataset to get insights of difference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "Name = \"MohammadParsa Dini\"\n",
        "Student_Id = \"400101204\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here we need to install the library we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJLIhwxFJ40x"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ocZChACRKdsl"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric.data.in_memory_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSs6TJydJ40y"
      },
      "source": [
        "#### Graph data representations in PyG\n",
        "Given a *sparse* **Graph** $\\mathcal{G}=(\\mathbf{X}, (\\mathbf{I}, \\mathbf{E}))$ with **node features** $\\mathbf{X} \\in \\mathbb{R}^{|V| \\times F}$, **edge indices $\\mathbf{I} \\in \\{1, \\cdots, N\\}^{2 \\times |\\mathcal{E}|}$**, (optional) **edge features** $\\mathbf{E} \\in \\mathbb{R}^{|\\mathcal{E} \\times D|}$, it is described by an instance of class `torch_geometric.data.Data`, which holds the corresponding attributes.\n",
        "\n",
        "We show a simple example of an unweighted and directed graph with four nodes and three edges.\n",
        "\n",
        "<p align=\"center\"><img width=\"20%\" src=\"figures/graph_data.png\"></p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocoEw2uJJ40y",
        "outputId": "107c6336-53f6-42bc-fdbb-92ff462fb0c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Data(x=[4, 1], edge_index=[2, 3])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# An example of creating a graph with 4 nodes and 3 edges in PyTorch Geometric\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Define edge_index in COO format [2, num_edges]\n",
        "edge_index = torch.tensor([\n",
        "    [1, 2, 3],  # source nodes (x2, x3, x4)\n",
        "    [0, 0, 0]   # target node (x1)\n",
        "], dtype=torch.long)\n",
        "\n",
        "# Define node features (here we use dummy features, e.g., 1 features per node)\n",
        "x = torch.tensor([\n",
        "    [1],  # x1\n",
        "    [1],  # x2\n",
        "    [1],  # x3\n",
        "    [1],  # x4\n",
        "], dtype=torch.float)\n",
        "\n",
        "# Create the graph data object\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZSyeK-J40z"
      },
      "source": [
        "#### Abstract Message Passing Scheme in PyG\n",
        "\n",
        "PyTorch Geometric provides the `torch_geometric.nn.MessagePassing` base class, which helps in creating such kinds of message passing graph neural networks by automatically taking care of message propagation. The implementation is decoupled into **UPDATE**, **AGGREGATION**, **MESSAGE** functions as:\n",
        "$$\n",
        "    \\mathbf{x}_i^{(k)} = \\mathrm{UPDATE} \\left( \\mathbf{x}_i, , \\mathrm{AGGR}_{j \\in \\mathcal{N}(i)} \\, \\mathrm{MESSAGE}^{(k)}\\left(\\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)},\\mathbf{e}_{i,j}\\right) \\right)    \n",
        "$$\n",
        "\n",
        "<p align=\"center\"><img width=\"35%\" src=\"figures/message_passing.png\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtmjhAaaJ40z"
      },
      "source": [
        "#### Implementing the GCN layer (lecture)\n",
        "\n",
        "The graph convolutional operator introduced by Kipf & Welling (ICLR 2017) is defined as\n",
        "$$\n",
        "        \\mathbf{X}^{k} = \\mathbf{\\hat{D}}^{-1/2} \\mathbf{\\hat{A}}\n",
        "        \\mathbf{\\hat{D}}^{-1/2} \\mathbf{X}^{k-1} \\mathbf{\\Theta},\n",
        "$$\n",
        "where $\\mathbf{\\hat{A}} = \\mathbf{A} + \\mathbf{I}$ denotes the adjacency matrix with inserted self-loops and\n",
        "$\\hat{D}_{ii} = \\sum_{j=0} \\hat{A}_{ij}$ its diagonal degree matrix. It is equivalent as:\n",
        "$$\n",
        "\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{ i \\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{deg(j)}} \\cdot \\left( \\mathbf{x}_j^{(k-1)}\\mathbf{\\Theta} \\right),\n",
        "$$\n",
        "\n",
        "where neighboring node features are first transformed by a weight matrix $\\mathbf{\\Theta}$, normalized by their degree, and finally summed up.\n",
        "This formula can be divided into the following steps:\n",
        "\n",
        "1. Add self-loops to the adjacency matrix.\n",
        "2. Linearly transform node feature matrix.\n",
        "3. Normalize node features.\n",
        "4. Sum up neighboring node features.\n",
        "5. Return new node embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8uJ-TSWcJ40z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.nn import MessagePassing\n",
        "import math\n",
        "\n",
        "def glorot(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)\n",
        "\n",
        "\n",
        "def add_self_loops(edge_index, num_nodes=None):\n",
        "    loop_index = torch.arange(0, num_nodes, dtype=torch.long,\n",
        "                              device=edge_index.device)\n",
        "    loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n",
        "\n",
        "    edge_index = torch.cat([edge_index, loop_index], dim=1)\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "\n",
        "def degree(index, num_nodes=None, dtype=None):\n",
        "    out = torch.zeros((num_nodes), dtype=dtype, device=index.device)\n",
        "    return out.scatter_add_(0, index, out.new_ones((index.size(0))))\n",
        "\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot(self.lin.weight)\n",
        "        zeros(self.lin.bias)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        ## TODO  \n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        N = x.size(0) # num of nodes\n",
        "        edge_index = add_self_loops(edge_index, N)\n",
        "        \n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        x = self.lin(x)\n",
        "        return self.propagate(edge_index, x=x)#,norm=norm)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        ## TODO\n",
        "        # Step 3: Normalize node features.\n",
        "        \n",
        "        #x_j has shape [E, out_channels]\n",
        "        row, col = edge_index\n",
        "        N = size[1]\n",
        "        deg = degree(col, N, dtype=x_j.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0 # sanity check for inf\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        deg_i = degree(row, num_nodes=size[0], dtype=x_j.dtype)\n",
        "        deg_inv_sqrt_i = deg_i.pow(-0.5)  # 1 / sqrt(deg(i))\n",
        "        deg_inv_sqrt_i[deg_inv_sqrt_i == float('inf')] = 0\n",
        "        \n",
        "        # Normalize: x_j * 1 / sqrt(deg(i)) * 1 / sqrt(deg(j))\n",
        "        norm = deg_inv_sqrt_i[row] * deg_inv_sqrt[col]\n",
        "        \n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        # aggr_out has shape [N, out_channels]\n",
        "\n",
        "        # Step 5: Return new node embeddings.\n",
        "        return aggr_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def glorot(tensor):\n",
        "    if tensor is not None:\n",
        "        stdv = math.sqrt(6.0 / (tensor.size(-2) + tensor.size(-1)))\n",
        "        tensor.data.uniform_(-stdv, stdv)\n",
        "\n",
        "def zeros(tensor):\n",
        "    if tensor is not None:\n",
        "        tensor.data.fill_(0)\n",
        "\n",
        "def add_self_loops(edge_index, num_nodes):\n",
        "    loop_index = torch.arange(0, num_nodes, dtype=torch.long, device=edge_index.device)\n",
        "    loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n",
        "    edge_index = torch.cat([edge_index, loop_index], dim=1)\n",
        "    return edge_index\n",
        "\n",
        "def degree(index, num_nodes, dtype=None):\n",
        "    out = torch.zeros(num_nodes, dtype=dtype, device=index.device)\n",
        "    return out.scatter_add_(0, index, out.new_ones(index.size(0)))\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNConv, self).__init__(aggr='add')\n",
        "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot(self.lin.weight)\n",
        "        zeros(self.lin.bias)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x: [N, in_channels], edge_index: [2, E]\n",
        "        # CHANGE HERE: Compute num_nodes and pass size to propagate\n",
        "        num_nodes = x.size(0)\n",
        "        edge_index = add_self_loops(edge_index, num_nodes)\n",
        "        x = self.lin(x)\n",
        "        return self.propagate(edge_index, x=x, size=(num_nodes, num_nodes))  # Pass size\n",
        "\n",
        "    def message(self, x_j, edge_index, size):\n",
        "        # x_j: [E, out_channels]\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, num_nodes=size[1], dtype=x_j.dtype)  # Target node degrees\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "        deg_i = degree(row, num_nodes=size[0], dtype=x_j.dtype)  # Source node degrees\n",
        "        deg_inv_sqrt_i = deg_i.pow(-0.5)\n",
        "        deg_inv_sqrt_i[deg_inv_sqrt_i == float('inf')] = 0\n",
        "        norm = deg_inv_sqrt_i[row] * deg_inv_sqrt[col]\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGaeZ4i_J40z"
      },
      "source": [
        "#### Implementing GraphSAGE (lab)\n",
        "\n",
        "The algorithm of GraphSAGE (*Inductive Representation Learning on Large Graphs (NIPS 2017)*) embedding generation is described as:\n",
        "\n",
        "<p align=\"center\"><img width=\"45%\" src=\"figures/graphsage.png\"></p>\n",
        "\n",
        "You are required to implement this algortihm with **MEAN/SUM/MAX** AGGREGATE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "e7uyZeVsJ400"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "def uniform(size, tensor):\n",
        "    bound = 1.0 / math.sqrt(size)\n",
        "    if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "\n",
        "class SAGEConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, aggr):\n",
        "        super(SAGEConv, self).__init__(aggr=aggr)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(2 * in_channels, out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        uniform(self.weight.size(0), self.weight)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \n",
        "        ## TODO\n",
        "        out= self.propagate(edge_index, x=x)\n",
        "        x_concat = torch.cat([x, out], dim=-1)\n",
        "        out = torch.matmul(x_concat, self.weight)\n",
        "        \n",
        "        return out\n",
        "\n",
        "        \n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "\n",
        "        ## TODO\n",
        "        if edge_weight is not None:\n",
        "            x_j = x_j * edge_weight.view(-1, 1)  # Element-wise multiplication\n",
        "        \n",
        "        return x_j\n",
        "\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "\n",
        "        ## TODO\n",
        "        return aggr_out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UULqDwVbJ400"
      },
      "source": [
        "## Vertex Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "B5kBXxMDJ400"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "path = osp.join(os.getcwd(), 'data', 'Cora')\n",
        "dataset = Planetoid(path, 'Cora')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YQCjdwbVJ400"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from torch import tensor\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.device = 'cuda'\n",
        "# else:\n",
        "#     torch.device = 'cpu'\n",
        "    \n",
        "# device = torch.device\n",
        "\n",
        "assert isinstance(torch.device, type), \"torch.device has been overwritten. Restart the kernel.\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# This function handles the training, evaluation, and timing of a GNN model over multiple runs. \n",
        "def run(dataset, model, runs, epochs, lr, weight_decay, early_stopping):\n",
        "\n",
        "    val_losses, accs, durations = [], [], []\n",
        "    for _ in range(runs):\n",
        "        data = dataset[0]\n",
        "        data = data.to(device)\n",
        "\n",
        "        \n",
        "        model.to(device).reset_parameters()\n",
        "\n",
        "        ## TODO \n",
        "        # use Adam optimizer\n",
        "        optimizer = Adam(model.parameters(),lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_start = time.perf_counter()\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        test_acc = 0\n",
        "        val_loss_history = []\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train(model, optimizer, data)\n",
        "            eval_info = evaluate(model, data)\n",
        "            eval_info['epoch'] = epoch\n",
        "\n",
        "            if eval_info['val_loss'] < best_val_loss:\n",
        "                best_val_loss = eval_info['val_loss']\n",
        "                test_acc = eval_info['test_acc']\n",
        "\n",
        "            val_loss_history.append(eval_info['val_loss'])\n",
        "\n",
        "            if early_stopping > 0 and epoch > epochs // 2:\n",
        "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
        "                if eval_info['val_loss'] > tmp.mean().item():\n",
        "                    break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "\n",
        "        val_losses.append(best_val_loss)\n",
        "        accs.append(test_acc)\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))\n",
        "\n",
        "\n",
        "def train(model, optimizer, data):\n",
        "    ## TODO\n",
        "    # Step 1: Set model to training mode.\n",
        "    model.train()\n",
        "    # Step 2: Zero the gradients of the optimizer.\n",
        "    optimizer.zero_grad()\n",
        "    # Step 3: Forward pass through the model to get the output logits.\n",
        "    logits = model(data)\n",
        "    # Step 4: Compute the loss using negative log likelihood loss.\n",
        "    loss = F.nll_loss(logits[data.train_mask], data.y[data.train_mask])\n",
        "    # Step 5: Backward pass to compute gradients.\n",
        "    loss.backward()\n",
        "    # Step 6: Update the weights using the optimizer.\n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits = model(data) \n",
        "\n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data['{}_mask'.format(key)]\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "\n",
        "        outs['{}_loss'.format(key)] = loss\n",
        "        outs['{}_acc'.format(key)] = acc\n",
        "\n",
        "    return outs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run(dataset, model, runs, epochs, lr, weight_decay, early_stopping):\n",
        "    val_losses, accs, durations = [], [], []\n",
        "    for _ in range(runs):\n",
        "        data = dataset[0]\n",
        "        data = data.to(device)\n",
        "        model.to(device).reset_parameters()\n",
        "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_start = time.perf_counter()\n",
        "        best_val_loss = float('inf')\n",
        "        test_acc = 0\n",
        "        val_loss_history = []\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train(model, optimizer, data)\n",
        "            eval_info = evaluate(model, data)\n",
        "            eval_info['epoch'] = epoch\n",
        "\n",
        "            if eval_info['val_loss'] < best_val_loss:\n",
        "                best_val_loss = eval_info['val_loss']\n",
        "                test_acc = eval_info['test_acc']\n",
        "\n",
        "            val_loss_history.append(eval_info['val_loss'])\n",
        "\n",
        "            if early_stopping > 0 and epoch > epochs // 2:\n",
        "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
        "                if eval_info['val_loss'] > tmp.mean().item():\n",
        "                    break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "        val_losses.append(best_val_loss)\n",
        "        accs.append(test_acc)\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))\n",
        "\n",
        "def train(model, optimizer, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(data)\n",
        "    loss = F.nll_loss(logits[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data['{}_mask'.format(key)]\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        outs['{}_loss'.format(key)] = loss\n",
        "        outs['{}_acc'.format(key)] = acc\n",
        "    return outs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7dpGcZAJ400"
      },
      "source": [
        "#### Build the model with GCN on vertex classification (lecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.7452, Test Accuracy: 0.798 ± 0.008, Duration: 6.482\n"
          ]
        }
      ],
      "source": [
        "## TODO \n",
        "# set hyperparameters\n",
        "\n",
        "runs = 10\n",
        "epochs = 200\n",
        "lr = 1e-2\n",
        "weight_decay = 5e-4\n",
        "early_stopping = 10\n",
        "hidden = 16\n",
        "dropout = 0.5\n",
        "\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        ## TODO\n",
        "        self.conv1 = GCNConv(dataset.num_features, hidden)\n",
        "        self.conv2 = GCNConv(hidden, dataset.num_classes)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "        ## TODO\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x,p=dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "run(dataset, Net(dataset), runs, epochs, lr, weight_decay, early_stopping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oeUsAT-J401"
      },
      "source": [
        "#### Build models with GraphSAGE on vertex classification (lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GraphSAGE-mean\n",
            "Val Loss: 0.7619, Test Accuracy: 0.790 ± 0.015, Duration: 0.905\n",
            "GraphSAGE-add\n",
            "Val Loss: 1.0896, Test Accuracy: 0.738 ± 0.028, Duration: 0.775\n",
            "GraphSAGE-max\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USER\\anaconda3\\envs\\myenv\\Lib\\site-packages\\torch_geometric\\warnings.py:11: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss: 0.9350, Test Accuracy: 0.762 ± 0.015, Duration: 0.951\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch.nn import Parameter\n",
        "import time\n",
        "from torch import tensor\n",
        "from torch.optim import Adam\n",
        "import math\n",
        "\n",
        "# Ensure torch.device is not overwritten\n",
        "assert isinstance(torch.device, type), \"torch.device has been overwritten. Restart the kernel.\"\n",
        "\n",
        "# Load Cora dataset\n",
        "path = osp.join(os.getcwd(), 'data', 'Cora')\n",
        "dataset = Planetoid(path, 'Cora')\n",
        "\n",
        "# Set hyperparameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "runs = 10\n",
        "epochs = 200\n",
        "lr = 1e-2\n",
        "weight_decay = 5e-4\n",
        "early_stopping = 10\n",
        "hidden = 16\n",
        "dropout = 0.5\n",
        "\n",
        "# SAGEConv implementation with fixed message method\n",
        "def uniform(size, tensor):\n",
        "    bound = 1.0 / math.sqrt(size)\n",
        "    if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "class SAGEConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, aggr):\n",
        "        super(SAGEConv, self).__init__(aggr=aggr)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.weight = Parameter(torch.Tensor(2 * in_channels, out_channels))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        uniform(self.weight.size(0), self.weight)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        out = self.propagate(edge_index, x=x)\n",
        "        x_concat = torch.cat([x, out], dim=-1)\n",
        "        out = torch.matmul(x_concat, self.weight)\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight):\n",
        "        # Fixed: Only apply edge_weight if it's a valid tensor\n",
        "        if edge_weight is not None and isinstance(edge_weight, torch.Tensor):\n",
        "            x_j = x_j * edge_weight.view(-1, 1)\n",
        "        return x_j\n",
        "\n",
        "    def update(self, aggr_out, x):\n",
        "        return aggr_out\n",
        "\n",
        "# Define SAGENet\n",
        "class SAGENet(torch.nn.Module):\n",
        "    def __init__(self, dataset, aggr='mean'):\n",
        "        super(SAGENet, self).__init__()\n",
        "        self.conv1 = SAGEConv(dataset.num_features, hidden, aggr=aggr)\n",
        "        self.conv2 = SAGEConv(hidden, dataset.num_classes, aggr=aggr)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Training and evaluation functions\n",
        "def run(dataset, model, runs, epochs, lr, weight_decay, early_stopping):\n",
        "    val_losses, accs, durations = [], [], []\n",
        "    for _ in range(runs):\n",
        "        data = dataset[0]\n",
        "        data = data.to(device)\n",
        "        model.to(device).reset_parameters()\n",
        "        optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_start = time.perf_counter()\n",
        "        best_val_loss = float('inf')\n",
        "        test_acc = 0\n",
        "        val_loss_history = []\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            train(model, optimizer, data)\n",
        "            eval_info = evaluate(model, data)\n",
        "            eval_info['epoch'] = epoch\n",
        "\n",
        "            if eval_info['val_loss'] < best_val_loss:\n",
        "                best_val_loss = eval_info['val_loss']\n",
        "                test_acc = eval_info['test_acc']\n",
        "\n",
        "            val_loss_history.append(eval_info['val_loss'])\n",
        "\n",
        "            if early_stopping > 0 and epoch > epochs // 2:\n",
        "                tmp = tensor(val_loss_history[-(early_stopping + 1):-1])\n",
        "                if eval_info['val_loss'] > tmp.mean().item():\n",
        "                    break\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        t_end = time.perf_counter()\n",
        "        val_losses.append(best_val_loss)\n",
        "        accs.append(test_acc)\n",
        "        durations.append(t_end - t_start)\n",
        "\n",
        "    loss, acc, duration = tensor(val_losses), tensor(accs), tensor(durations)\n",
        "    print('Val Loss: {:.4f}, Test Accuracy: {:.3f} ± {:.3f}, Duration: {:.3f}'.\n",
        "          format(loss.mean().item(),\n",
        "                 acc.mean().item(),\n",
        "                 acc.std().item(),\n",
        "                 duration.mean().item()))\n",
        "\n",
        "def train(model, optimizer, data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(data)\n",
        "    loss = F.nll_loss(logits[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "    outs = {}\n",
        "    for key in ['train', 'val', 'test']:\n",
        "        mask = data['{}_mask'.format(key)]\n",
        "        loss = F.nll_loss(logits[mask], data.y[mask]).item()\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        outs['{}_loss'.format(key)] = loss\n",
        "        outs['{}_acc'.format(key)] = acc\n",
        "    return outs\n",
        "\n",
        "# Run SAGENet with different aggregation methods\n",
        "aggrs = ['mean', 'add', 'max']\n",
        "for aggr in aggrs:\n",
        "    print('GraphSAGE-{}'.format(aggr))\n",
        "    run(dataset, SAGENet(dataset, aggr), runs, epochs, lr, weight_decay, early_stopping)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
